## Tutorial 1:31 Leon Van Zyl
https://www.youtube.com/watch?v=9TaRksXuLWY

Leon is one of the most respected Influencers teaching Flowise, and is sponsored by them the last I checked.

 Notes from his Youtube page at a point in time:

29,853 views Jan 5, 2025 [#flowiseai](https://www.youtube.com/hashtag/flowiseai)

FlowiseAI Complete Course (2025) Master no-code AI development with this comprehensive Flowise AI tutorial, covering everything from basic chatbots to advanced multi-agent systems and real-world integrations. Learn to build custom knowledge bases, deploy AI solutions, and create sophisticated workflows using large language models - all without writing code. Perfect for beginners and developers looking to harness the power of AI through a visual interface. 
Cloud: [https://flowiseai.com/auth/signup?ref...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbFY0Rmktb3RXdWJwSFVhQmY1TTFTTlFjZThtUXxBQ3Jtc0ttaS0ydFpoWjE0d3B0S2NnTWQydXRRQTVvU21FeDRKU1o3WFFBTWZSTVRvRDljWUdnSHRlOVBsM0JuMHY4a3VPY1Q3UEpJSUdHYjZIWmlZUDEyRXJRYnBlNFhZWVV4cWdTeC1ob0ItcmxfUGN1Ti1Ubw&q=https%3A%2F%2Fflowiseai.com%2Fauth%2Fsignup%3FreferralCode%3DLEONVZ&v=9TaRksXuLWY) 
Flowise Github: [https://github.com/FlowiseAI/Flowise](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbFJQbm4xa0x6blRaM0VjMkpDTnJ0ZF9QWWZZZ3xBQ3Jtc0ttY2JSNU43b3k0QUh1SE1CZ242QXJWTWE4cm1lbmpTdzdESkJyYlZlTTdjaGt6Sm9rTVVCVFlDYXNPdFM1YTJSa0dLOFpnV1Rsd19sTzdWSWtfUmlGUk0zdXdURWh6RUZSUm1heUJReVp3QWlvV3oyQQ&q=https%3A%2F%2Fgithub.com%2FFlowiseAI%2FFlowise&v=9TaRksXuLWY) 
Download Course Resources: [https://github.com/leonvanzyl/flowise...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbHdub2pONXhCX2lzcHg1dS0tR3lLNFpodWpCQXxBQ3Jtc0ttNHdhWk1RbkVsU09zdWRidUdvd3I1X2kwSFNOcUt2TEFQQ1V4X2hEYmxNa2tjNE5BeVhYdW5ncGdBZkFVLWRYckxyemxNNUduVXY4YVFGaDVFRHVqcWdtQmJsZG5TYWlYOWNXRjBudUFjZ1BKLWhwQQ&q=https%3A%2F%2Fgithub.com%2Fleonvanzyl%2Fflowise-masterclass-2025&v=9TaRksXuLWY) 
n8n Cloud: [https://n8n.partnerlinks.io/f7f19w3vrhin](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbUU3TnRzMzEyUUhhcnNKUVdEVHlaUWUyeFhSZ3xBQ3Jtc0tsbkZIWThkZEJ4V2FRMzY5aWpaWHNNc0tEb1Y1eWM1ejQ1TjhWSHNlMmZ0N0hXMDQxdi10ZHRLTUNkQkZDQkJaRVZHSG1udzZEUFJqSHhFUW5XcEF6QndQYnlIVVBPR3BlcFRyOGN0eEVRQ29HYmt5VQ&q=https%3A%2F%2Fn8n.partnerlinks.io%2Ff7f19w3vrhin&v=9TaRksXuLWY) 
Make.com: [https://www.make.com/en/register?pc=l...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbjVRX2syX2Nyc2xueFYwc2psOWk0QXB0dTBMd3xBQ3Jtc0trTV9yaVl1RHNKYUJzYzlfdjlTWTJwNEJxMG5aY3JEa01DX3JGbnk2YWNQa1B1STRlUG14V1pzQk5raVRuaFE5cVctMUxyLTFGalVCbkd5U2xyeFhGbFpfTVJycTBiejJ5OEtKdjRWTmR2SjNrcWRncw&q=https%3A%2F%2Fwww.make.com%2Fen%2Fregister%3Fpc%3Dleonvanzyl&v=9TaRksXuLWY) 
Referenced videos: Ollama & Flowise Tutorial:    [![](https://www.gstatic.com/youtube/img/watch/yt_favicon_ringo2.png)
Build Your Own ChatGPT Alternative FR... [Build Your Own ChatGPT Alternative FR...](https://www.youtube.com/watch?v=lJOZiRoZNJw)  
Sequential Agents:    [![](https://www.gstatic.com/youtube/img/watch/yt_favicon_ringo2.png) • Master Sequential Agents: Build Compl...](https://www.youtube.com/watch?v=6LbvgTbS0BE)   
FlowiseAI Playlist:    [![](https://www.gstatic.com/youtube/img/watch/yt_favicon_ringo2.png) • Flowise AI (2024) Tutorial](https://www.youtube.com/playlist?list=PL4HikwTaYE0H7wBxhvQqxYcKOkZ4O3zXh) 

## GEMINI SUMMARY of the first video:

### **Overview of Flowise AI**

Flowise AI is an open-source, low-code tool for building customized LLM orchestration flows and AI agents. It uses nodes to create workflows, allowing easy swapping of components like LLM providers. Flowise can be accessed locally, through a paid cloud service, or by self-hosting on cloud platforms like Render. It supports creating chat flows, agent flows, and assistants, and provides a marketplace for templates and tools. Flowise includes features for managing credentials, setting global variables, creating API keys, and handling document stores.


### **Step-wise Actions Summarized**

### **Accessing Flowise:** 
Local Setup:
- Install Node.js from nodejs.org.
- Open command prompt or terminal and run `npx flow-wise start`.
- Access Flowise in your browser at `localhost:3000`. >Flowise Cloud:
- Sign up for the paid Flowise cloud service.
	- Use affiliate link for potential access. >Cloud Self Host:
- Create a free account on render.com.
	- Fork the Flowise GitHub repository.
	- In Render, add a new web service and connect to your GitHub repo.
	- Configure environment variables:
	- `Flow-wise_username`: Set your username.
	- `Flow-wise_password`: Set your password.
	- `port`: Set to 3000.
	- `node_version`: Set to 18.18.1.
	- (Optional for persistent storage):
	- `API_KEY_PATH`: `/opt/render/.Flowise`.
	- `DATABASE_PATH`: `/opt/render/.Flowise`.
	- `LOG_PATH`: `/opt/render/.Flowise/logs`.
	- `SECRET_PATH`: `/opt/render/.Flowise`.
	- Add a disk in advanced settings with the mount path `/opt/render/.Flowise` and disk size 1GB.
	- Deploy the web service.
	- Access Flowise via the provided URL using your username and password.
- To Update Flowise by syncing your forked repository. Sync for ... This branch is .. n behind. Sync fork ... 
	- Notes on first Chat Flow:
		- Worked for me:
			- Gemini worked using my key
		- Did work for  - sometimes the boxes wouldn't let me connect to the Chat flow at all and the dot turned red.
			- Anthropic didn't using my key, with Verity key
			- OpenAI didn't using my key
			- OpenAI didn't using Scots key
			- Ollama didn't with it running on my machine... (of course it's not running out on GCP, duh) I don't know if the flow can get to my localhost:11434 but I doubt it.
			- Grok didn't using Groq chat box, and my key
			- Grok Didn't using Scots Key
			- ``` When a component in Flowise has a red dot and won't connect to the Chatflow, it usually indicates a configuration issue or incompatibility between the connected components. Here's a breakdown of potential reasons:
			- **Missing or Incorrect Credentials:** Some Chat components, like certain LLMs or databases, require credentials to be configured. If these are missing or incorrect, the component may fail to connect.
			- **Incompatible Node Connections:** Ensure that you are connecting nodes that are compatible with each other. For example, you can't directly connect an output from the Langchain component to a component designed for a different framework.
			- Improper Configuration:** Check that each component is properly configured according to its specific requirements
			- **Conflicting Dependencies:** There may be instances where different components in your Chatflow have conflicting dependencies.
			- Yes, Flowise has error logs that can help you troubleshoot issues. Based on the search results, here's where you can find them:
	- Chatflow Settings:
		- Messages are kept to review
		- Response to responses can be set in Chatflow settings.
		- Rate limits can be set in settings.
		- Starter prompts
			- Follow-up prompts
				- Requires that we set an LLM to analyze the response and suggest others 
					- Have to set n LLM with a key for this.
			- Speech to Text ...
			- Chat Feedback
				-  +/-1 as well as add additional feedback comment.
			- Analyze Chatflow (Tools)
				- Langsmith - https://www.langchain.com/langsmith
					- LangSmith is an all-in-one developer platform for every step of the LLM-powered application lifecycle, whether you’re building with LangChain or not.  
Debug, collaborate, test, and monitor your LLM applications
			- Langfuze
			- Leeds
			- File Uploads
- Embed code...
- share chatbot .. Share url ... Not good if self hosting.... 
- Unstructured information from an invoice example - difficult to do using traditional cloding methods.
	- (timestamp 33:19)
	- Doesn't have to be a pdf, could be images... like screenshots and jpegs as well.
	- Can ask LLM to extract certain information.
	- More importantly we want to return that information in a very specific format.

- **Location:** The logs are typically stored in the `.flowise/logs` directory. This directory is located relative to where you are running Flowise.
- **File Names:**
    - `server-error.log`: This file contains error logs, including stack traces, which provide detailed information about the errors encountered.

By examining these log files, especially `server-error.log`, you can get more specific information about why your Chat components are not connecting, and hopefully resolve the red dot issue.

To troubleshoot, you can:

1. **Check Component Documentation:** Refer to the Flowise documentation for the specific Chat component you are using to understand its requirements and connection compatibility.
2. **Inspect Error Messages:** If there are any error messages displayed in the Flowise interface, carefully examine them for clues about the issue.
3. **Double-check Node Connections:** Ensure you have connected output to input correctly. ```
			- 

**Chat flows**: Conversational chatbots, AI agents, or assistants
**Agent Flows:** multiple agents
**Assistant Flows:**  we can easily create assistants which contain custom knowledge bases and tools by effectively following a very simple
wizard. 
Marketplace has template that you can copy over and change as you see fit.
*OLLAMA* to run dedicated models on your machine ...
About 19 minutes in he starts building.
Goes over the UI of the canvas about 20:00-21:00	
Chat Prompt is the Conversational flow...
	Flowise allowed 

All projects must contain either Agents or chains.
Messages that occurred within the run of the flow are stored under the Gear, as well as total Feedback received.
System Prompt with HomerSimpson Donut bot worked in this case.


### **Building a ChatGPT Clone:**
- Create a new chat flow and save it.
- Add a conversation chain node.
- Add a buffer window memory node and connect it to the chain. Set the size (e.g., 20 messages).
- Add a chat model node (e.g., Chat OpenAI) and connect it to the chain. Configure credentials and model settings.
- (Optional) Add a system prompt to the chain's additional parameters to customize the chatbot's behavior.
- Test the chat flow using the chat window.
- Configure settings like starter prompts, follow-up prompts, chat feedback, and lead collection.
- Enable file uploads in settings > configuration.
- Share the chatbot via API endpoint or by making it public.

33:00
### **Building an Invoice Analyzer:**  - the main difference is the output parser to specify the output kind and style
 Create a new chat flow and save it.
- Add an LLM chain node.
- Add a chat model node (e.g., Chat OpenAI) and connect it to the chain.
- Add a prompt template node and connect it to the chain.
- Configure the prompt template to extract specific information (e.g., invoice number, customer number, gross amount). 
- ``` Extract the following information from this letter employee verifcation letter
-The date of hire
-The date of the letter
-The job title that the employee held
LETTER:
{letter}```
- Use variables like `invoice_content` to inject data.
	- to do this in the Prompt template after specifying the values to look for, you need to create a value that is a variable. 
	  INVOICE:
	  {invoice}
	- ![[Screenshot 2025-03-19 at 6.57.54 AM.png]]
- Click on Format Prompt Values
	- ![[Screenshot 2025-03-19 at 7.04.31 AM.png]]
- ![[Screenshot 2025-03-19 at 7.04.43 AM.png]]
- ![[Screenshot 2025-03-19 at 7.04.51 AM.png]]
- We won't see anywhere to upload a file yet.
	- We need to go to settings, configuration.
	- Configuration is the gear
	- File upload is on the right of the menu and may be off the side of the page.
	- The slider in dark mode is looks like a dot, unless it is on.
	- ![[Screenshot 2025-03-19 at 7.40.12 AM.png]]
- Add a structured output parser node and connect it to the chain.
- Define the output structure in the output parser's additional parameters.
- Enable file uploads in settings > configuration.
- Test the chat flow by uploading an invoice file and sending a message.

### **Building a Research Agent:** 
Create a new chat flow and save it.
- Add a tool agent node.
- Add a chat model node (e.g., Chat OpenAI) and connect it to the agent.
- Add a buffer window memory node and connect it to the agent.
- Add tool nodes (e.g., calculator, SERP API) and connect them to the agent. Configure credentials for external tools.
- (Optional) Add custom tools from the marketplace.
- Test the agent by sending messages.

### **Building a Customer Support Agent:** 
- Create a new chat flow and save it.
- Add a tool agent node.
- Add a chat model node (e.g., Chat OpenAI) and connect it to the agent.
- Add a buffer window memory node and connect it to the agent.
- Configure the agent's system prompt.
- Create a document store in the document stores menu.
- Add document loaders (e.g., docx file loader, CSV file loader) to the document store.
- Configure a text splitter for document chunks.
- Upsert the document store into a vector store (e.g., Pinecone). Configure embeddings and vector store credentials.
- Add a retriever tool node and connect it to the agent.
- Add a document store node and connect it to the retriever tool. Select the created document store.
- Test the agent by sending messages.
- Embed the chatbot into a website using the provided script.

### **Using Custom Assistants:** 
- - Create a new custom assistant and give it a name.
- Select a model, set a system prompt, and choose a document store.
- Add tools to the assistant.
- Test the assistant using the preview window.
- Embed the assistant into a website using the provided script.

### **Creating Multi-Agent Flows:** 
- Create a new agent flow and save it.
- Add a supervisor node and connect a chat model.
- Add worker nodes and connect them to the supervisor.
- Configure each worker node with a name, prompt, and optional tools or chat model.
- Test the multi-agent flow.
- (Optional) Use the prompt engineering team template from the marketplace to generate worker prompts.

### **Creating Sequential Agent Flows:** 
- Create a new agent flow and save it.
- Add a start node and connect a chat model and memory node.
- Add an agent node and connect it to the start node. Configure tools and a system prompt.
- Add a condition node to conditionally call other nodes.
- Add an LLM node for reviews and connect it to the condition node.
- Add a loop node to loop back to the agent node.
- Add an end node and connect it to the condition node's end output.
- Test the sequential agent flow.

### **Integrating Flowise with Telegram:** 
- Export a flow from local Flowise and import it into a cloud instance. - Create an n8n workflow. - Add a Telegram trigger node and configure credentials using BotFather. - Add an HTTP request node to call the Flowise API endpoint. - Add a Telegram send a text message node to send responses back to Telegram. - Configure the n8n workflow to pass messages and chat IDs between Telegram and Flowise. - Test and activate the n8n workflow.

**Terminology**
- Agent Flow: A workflow that contains multiple agents.
- Agent: A more autonomous and intelligent component in FlowiseAI that can make decisions and utilize tools to achieve a goal.
- API Key: A unique identifier used to authenticate and authorize access to an API (Application Programming Interface).
- API: Application Programming Interface.
- Chain: A linear sequence of components in FlowiseAI designed to process language in a specific order.
- Chat ID: A unique identifier for a specific chat or user in Telegram.
- Cloud Instance: Deploying and running FlowiseAI on a remote server, such as those provided by Render or Railway.
- Condition Node: A component in sequential agents that allows the flow to branch based on certain criteria.
- Credentials: Securely stored information (like API keys) required to access external services.
- Docker: A platform for developing, shipping, and running applications in containers.
- Document Store: A component in FlowiseAI used to store and manage collections of documents for knowledge retrieval.
- Embeddings: Numerical representations of text that capture its semantic meaning, used for comparing the similarity between pieces of text.
- Environment Variables (Render): Dynamic named values that can affect the way running processes will behave on the Render platform.
- Export/Import Flow: The process of saving a FlowiseAI workflow to a file and loading it into another instance.
- FlowiseAI: A visual platform that allows users to build custom AI workflows and agents without writing code.
- Fork: A copy of a repository on GitHub.
- GitHub: A web-based platform used for version control and collaboration on software development projects.
- Global Variables: Variables that can be defined and accessed by all flows within a FlowiseAI instance.
- Human in the Loop: A feature that allows for human intervention and approval during the execution of an AI workflow.
- Large Language Model (LLM): A deep learning model trained on a massive amount of text data, capable of understanding and generating human-like language (e.g., GPT-4, Claude, Llama).
- Local Instance: Running FlowiseAI directly on your own computer.
- Loop Node: A component in sequential agents that allows for repeating a previous step in the flow.
- Marketplace: A section within FlowiseAI where users can discover and add pre-built tools and components.
- Memory: The ability of a chat flow or agent to retain information from previous interactions.
- Multi-Agent: A system with multiple agents working together. An approach in FlowiseAI where multiple AI agents work together to solve a complex task, often with a supervisor agent managing the process.
- n8n (or Make.com): Automation platforms that can be used to integrate FlowiseAI with other applications and services, like Telegram. A workflow automation tool.
- Node.js: A JavaScript runtime environment that allows you to run JavaScript on the server-side.
- Node: A building block in a FlowiseAI workflow, representing a specific action or component (e.g., a language model, a tool, memory).
- npx: A package runner tool that comes bundled with npm (Node Package Manager), often used to execute Node.js packages.
- Output Parser: A tool for structuring the output of an LLM.
- Prompt Template: A predefined structure for providing instructions to an LLM.
- Prompt: The input text provided to an LLM to guide its response.
- Record Manager: A tool for managing and tracking data changes. A component used to track and manage documents that have been processed and added to a vector store, preventing duplicates.
- Render: A cloud platform for deploying web applications.
- Retriever Tool: A FlowiseAI tool that fetches relevant documents from a document store based on a user's query.
- Sequential Agents: An approach in FlowiseAI where a series of agents execute tasks in a predefined order.
- SERP API: Search Engine Results Page API.
- Supervisor Node: An agent in a multi-agent system responsible for delegating tasks and managing the workflow of other agents.
- System Prompt: A specific type of prompt used to define the behavior, role, and persona of a chatbot or agent.
- Telegram Bot: A third-party application that runs inside Telegram, often used for automated messaging and interactions.
- Telegram: A messaging platform.
- Text Splitter: A process of dividing large documents into smaller, more manageable chunks.
- Tool: An external function or integration that an AI agent can use to perform specific tasks (e.g., searching the web, performing calculations).
- Upsert: An operation that inserts new data or updates existing data in a database or store.
- Vector Store: A type of database optimized for storing and querying vector embeddings.
- Worker Node: An individual agent within a multi-agent system that performs specific sub-tasks.
- Workflow (or Flow): A sequence of interconnected nodes in FlowiseAI that defines a specific AI task or application.

You can host Flowise Cloud ... it makes things easy.

Affiliate link - signup using github or google with a 14 free trial period - with access to more features (teams and team members to collaborate with team members )

Making money with the flows ore - self deploying...
in the documentation with documentation... he uses Render for self hosting.

